{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# RAG - E2E Example\n",
    "- Chunking\n",
    "- Simple 'Imaginary' Embedding Model - assuming 2 numbers in Text embeddings (vectors) 1:2 dimension (1 row 2 items) each - 1)How much text talks about Medical stuff ; 2)How much text talks about Software stuff.\n",
    "- Normalisation in results of Text embeddings\n",
    "- Store embeddings in Vector Database\n",
    "- User Query -> Embedding Model (same model) -> Find Closest Embedding (Search)\n",
    "- Search: Semantic Search (Embeddings + VectorDB) + Lexical Search (classic text search/BM25) > MERGE RESULTS\n",
    "- Create Prompt in Messages[] with 1)Prompt to Claude 2)User Query 3)Closest embedding (chunk) from semantic search, send to Claude for an answer. Return to user."
   ],
   "id": "e1aa1cfcc8c2a96c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T09:59:11.885610Z",
     "start_time": "2025-09-10T09:59:11.880666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import voyageai\n",
    "# Client Setup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = voyageai.Client()"
   ],
   "id": "9bd0fd74b0087c9a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T09:59:11.894482Z",
     "start_time": "2025-09-10T09:59:11.891401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chunk by section\n",
    "import re\n",
    "\n",
    "\n",
    "def chunk_by_section(document_text):\n",
    "    pattern = r\"\\n## \"\n",
    "    return re.split(pattern, document_text)\n",
    "\n",
    "\n",
    "# Embedding Generation\n",
    "def generate_embedding(chunks,\n",
    "                       #model=\"voyage-3-large\",\n",
    "                       model=\"voyage-3-lite\",  #Avoid rate limiting\n",
    "                       input_type=\"query\"):\n",
    "    is_list = isinstance(chunks, list)\n",
    "    input = chunks if is_list else [chunks]\n",
    "    result = client.embed(input, model=model, input_type=input_type)\n",
    "    return result.embeddings if is_list else result.embeddings[0]"
   ],
   "id": "ceb0bfc0bff72eca",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T09:59:11.913533Z",
     "start_time": "2025-09-10T09:59:11.901040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# VectorIndex implementation (SEMANTIC SEARCH)\n",
    "from typing import Any, List, Dict, Tuple\n",
    "\n",
    "\n",
    "class VectorIndex:\n",
    "    def __init__(\n",
    "            self,\n",
    "            distance_metric: str = \"cosine\",\n",
    "            embedding_fn=None,\n",
    "    ):\n",
    "        self.vectors: List[List[float]] = []\n",
    "        self.documents: List[Dict[str, Any]] = []\n",
    "        self._vector_dim: Optional[int] = None\n",
    "        if distance_metric not in [\"cosine\", \"euclidean\"]:\n",
    "            raise ValueError(\"distance_metric must be 'cosine' or 'euclidean'\")\n",
    "        self._distance_metric = distance_metric\n",
    "        self._embedding_fn = embedding_fn\n",
    "\n",
    "    def add_document(self, document: Dict[str, Any]):\n",
    "        if not self._embedding_fn:\n",
    "            raise ValueError(\n",
    "                \"Embedding function not provided during initialization.\"\n",
    "            )\n",
    "        if not isinstance(document, dict):\n",
    "            raise TypeError(\"Document must be a dictionary.\")\n",
    "        if \"content\" not in document:\n",
    "            raise ValueError(\n",
    "                \"Document dictionary must contain a 'content' key.\"\n",
    "            )\n",
    "\n",
    "        content = document[\"content\"]\n",
    "        if not isinstance(content, str):\n",
    "            raise TypeError(\"Document 'content' must be a string.\")\n",
    "\n",
    "        vector = self._embedding_fn(content)\n",
    "        self.add_vector(vector=vector, document=document)\n",
    "\n",
    "    def search(\n",
    "            self, query: Any, k: int = 1\n",
    "    ) -> List[Tuple[Dict[str, Any], float]]:\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "\n",
    "        if isinstance(query, str):\n",
    "            if not self._embedding_fn:\n",
    "                raise ValueError(\n",
    "                    \"Embedding function not provided for string query.\"\n",
    "                )\n",
    "            query_vector = self._embedding_fn(query)\n",
    "        elif isinstance(query, list) and all(\n",
    "                isinstance(x, (int, float)) for x in query\n",
    "        ):\n",
    "            query_vector = query\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Query must be either a string or a list of numbers.\"\n",
    "            )\n",
    "\n",
    "        if self._vector_dim is None:\n",
    "            return []\n",
    "\n",
    "        if len(query_vector) != self._vector_dim:\n",
    "            raise ValueError(\n",
    "                f\"Query vector dimension mismatch. Expected {self._vector_dim}, got {len(query_vector)}\"\n",
    "            )\n",
    "\n",
    "        if k <= 0:\n",
    "            raise ValueError(\"k must be a positive integer.\")\n",
    "\n",
    "        if self._distance_metric == \"cosine\":\n",
    "            dist_func = self._cosine_distance\n",
    "        else:\n",
    "            dist_func = self._euclidean_distance\n",
    "\n",
    "        distances = []\n",
    "        for i, stored_vector in enumerate(self.vectors):\n",
    "            distance = dist_func(query_vector, stored_vector)\n",
    "            distances.append((distance, self.documents[i]))\n",
    "\n",
    "        distances.sort(key=lambda item: item[0])\n",
    "\n",
    "        return [(doc, dist) for dist, doc in distances[:k]]\n",
    "\n",
    "    def add_vector(self, vector, document: Dict[str, Any]):\n",
    "        if not isinstance(vector, list) or not all(\n",
    "                isinstance(x, (int, float)) for x in vector\n",
    "        ):\n",
    "            raise TypeError(\"Vector must be a list of numbers.\")\n",
    "        if not isinstance(document, dict):\n",
    "            raise TypeError(\"Document must be a dictionary.\")\n",
    "        if \"content\" not in document:\n",
    "            raise ValueError(\n",
    "                \"Document dictionary must contain a 'content' key.\"\n",
    "            )\n",
    "\n",
    "        if not self.vectors:\n",
    "            self._vector_dim = len(vector)\n",
    "        elif len(vector) != self._vector_dim:\n",
    "            raise ValueError(\n",
    "                f\"Inconsistent vector dimension. Expected {self._vector_dim}, got {len(vector)}\"\n",
    "            )\n",
    "\n",
    "        self.vectors.append(list(vector))\n",
    "        self.documents.append(document)\n",
    "\n",
    "    def _euclidean_distance(\n",
    "            self, vec1: List[float], vec2: List[float]\n",
    "    ) -> float:\n",
    "        if len(vec1) != len(vec2):\n",
    "            raise ValueError(\"Vectors must have the same dimension\")\n",
    "        return math.sqrt(sum((p - q) ** 2 for p, q in zip(vec1, vec2)))\n",
    "\n",
    "    def _dot_product(self, vec1: List[float], vec2: List[float]) -> float:\n",
    "        if len(vec1) != len(vec2):\n",
    "            raise ValueError(\"Vectors must have the same dimension\")\n",
    "        return sum(p * q for p, q in zip(vec1, vec2))\n",
    "\n",
    "    def _magnitude(self, vec: List[float]) -> float:\n",
    "        return math.sqrt(sum(x * x for x in vec))\n",
    "\n",
    "    def _cosine_distance(self, vec1: List[float], vec2: List[float]) -> float:\n",
    "        if len(vec1) != len(vec2):\n",
    "            raise ValueError(\"Vectors must have the same dimension\")\n",
    "\n",
    "        mag1 = self._magnitude(vec1)\n",
    "        mag2 = self._magnitude(vec2)\n",
    "\n",
    "        if mag1 == 0 and mag2 == 0:\n",
    "            return 0.0\n",
    "        elif mag1 == 0 or mag2 == 0:\n",
    "            return 1.0\n",
    "\n",
    "        dot_prod = self._dot_product(vec1, vec2)\n",
    "        cosine_similarity = dot_prod / (mag1 * mag2)\n",
    "        cosine_similarity = max(-1.0, min(1.0, cosine_similarity))\n",
    "\n",
    "        return 1.0 - cosine_similarity\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.vectors)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        has_embed_fn = \"Yes\" if self._embedding_fn else \"No\"\n",
    "        return f\"VectorIndex(count={len(self)}, dim={self._vector_dim}, metric='{self._distance_metric}', has_embedding_fn='{has_embed_fn}')\""
   ],
   "id": "14e18c16cddba2ec",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T09:59:11.927115Z",
     "start_time": "2025-09-10T09:59:11.917003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# BM25Index implementation (LEXICAL SEARCH)\n",
    "import math\n",
    "from collections import Counter\n",
    "from typing import Callable, Optional, Any, List, Dict, Tuple\n",
    "\n",
    "\n",
    "class BM25Index:\n",
    "    def __init__(\n",
    "            self,\n",
    "            k1: float = 1.5,\n",
    "            b: float = 0.75,\n",
    "            tokenizer: Optional[Callable[[str], List[str]]] = None,\n",
    "    ):\n",
    "        self.documents: List[Dict[str, Any]] = []\n",
    "        self._corpus_tokens: List[List[str]] = []\n",
    "        self._doc_len: List[int] = []\n",
    "        self._doc_freqs: Dict[str, int] = {}\n",
    "        self._avg_doc_len: float = 0.0\n",
    "        self._idf: Dict[str, float] = {}\n",
    "        self._index_built: bool = False\n",
    "\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self._tokenizer = tokenizer if tokenizer else self._default_tokenizer\n",
    "\n",
    "    def _default_tokenizer(self, text: str) -> List[str]:\n",
    "        text = text.lower()\n",
    "        tokens = re.split(r\"\\W+\", text)\n",
    "        return [token for token in tokens if token]\n",
    "\n",
    "    def _update_stats_add(self, doc_tokens: List[str]):\n",
    "        self._doc_len.append(len(doc_tokens))\n",
    "\n",
    "        seen_in_doc = set()\n",
    "        for token in doc_tokens:\n",
    "            if token not in seen_in_doc:\n",
    "                self._doc_freqs[token] = self._doc_freqs.get(token, 0) + 1\n",
    "                seen_in_doc.add(token)\n",
    "\n",
    "        self._index_built = False\n",
    "\n",
    "    def _calculate_idf(self):\n",
    "        N = len(self.documents)\n",
    "        self._idf = {}\n",
    "        for term, freq in self._doc_freqs.items():\n",
    "            idf_score = math.log(((N - freq + 0.5) / (freq + 0.5)) + 1)\n",
    "            self._idf[term] = idf_score\n",
    "\n",
    "    def _build_index(self):\n",
    "        if not self.documents:\n",
    "            self._avg_doc_len = 0.0\n",
    "            self._idf = {}\n",
    "            self._index_built = True\n",
    "            return\n",
    "\n",
    "        self._avg_doc_len = sum(self._doc_len) / len(self.documents)\n",
    "        self._calculate_idf()\n",
    "        self._index_built = True\n",
    "\n",
    "    def add_document(self, document: Dict[str, Any]):\n",
    "        if not isinstance(document, dict):\n",
    "            raise TypeError(\"Document must be a dictionary.\")\n",
    "        if \"content\" not in document:\n",
    "            raise ValueError(\n",
    "                \"Document dictionary must contain a 'content' key.\"\n",
    "            )\n",
    "\n",
    "        content = document.get(\"content\", \"\")\n",
    "        if not isinstance(content, str):\n",
    "            raise TypeError(\"Document 'content' must be a string.\")\n",
    "\n",
    "        doc_tokens = self._tokenizer(content)\n",
    "\n",
    "        self.documents.append(document)\n",
    "        self._corpus_tokens.append(doc_tokens)\n",
    "        self._update_stats_add(doc_tokens)\n",
    "\n",
    "    def _compute_bm25_score(\n",
    "            self, query_tokens: List[str], doc_index: int\n",
    "    ) -> float:\n",
    "        score = 0.0\n",
    "        doc_term_counts = Counter(self._corpus_tokens[doc_index])\n",
    "        doc_length = self._doc_len[doc_index]\n",
    "\n",
    "        for token in query_tokens:\n",
    "            if token not in self._idf:\n",
    "                continue\n",
    "\n",
    "            idf = self._idf[token]\n",
    "            term_freq = doc_term_counts.get(token, 0)\n",
    "\n",
    "            numerator = idf * term_freq * (self.k1 + 1)\n",
    "            denominator = term_freq + self.k1 * (\n",
    "                    1 - self.b + self.b * (doc_length / self._avg_doc_len)\n",
    "            )\n",
    "            score += numerator / (denominator + 1e-9)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def search(\n",
    "            self,\n",
    "            query_text: str,\n",
    "            k: int = 1,\n",
    "            score_normalization_factor: float = 0.1,\n",
    "    ) -> List[Tuple[Dict[str, Any], float]]:\n",
    "        if not self.documents:\n",
    "            return []\n",
    "\n",
    "        if not isinstance(query_text, str):\n",
    "            raise TypeError(\"Query text must be a string.\")\n",
    "\n",
    "        if k <= 0:\n",
    "            raise ValueError(\"k must be a positive integer.\")\n",
    "\n",
    "        if not self._index_built:\n",
    "            self._build_index()\n",
    "\n",
    "        if self._avg_doc_len == 0:\n",
    "            return []\n",
    "\n",
    "        query_tokens = self._tokenizer(query_text)\n",
    "        if not query_tokens:\n",
    "            return []\n",
    "\n",
    "        raw_scores = []\n",
    "        for i in range(len(self.documents)):\n",
    "            raw_score = self._compute_bm25_score(query_tokens, i)\n",
    "            if raw_score > 1e-9:\n",
    "                raw_scores.append((raw_score, self.documents[i]))\n",
    "\n",
    "        raw_scores.sort(key=lambda item: item[0], reverse=True)\n",
    "\n",
    "        normalized_results = []\n",
    "        for raw_score, doc in raw_scores[:k]:\n",
    "            normalized_score = math.exp(-score_normalization_factor * raw_score)\n",
    "            normalized_results.append((doc, normalized_score))\n",
    "\n",
    "        normalized_results.sort(key=lambda item: item[1])\n",
    "\n",
    "        return normalized_results\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.documents)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"BM25VectorStore(count={len(self)}, k1={self.k1}, b={self.b}, index_built={self._index_built})\""
   ],
   "id": "fbc90c3f5cc661a5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T09:59:11.934888Z",
     "start_time": "2025-09-10T09:59:11.929708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retriever - Class that merges Semantic Search (Embeddings/VectorDB search) + Lexical Search\n",
    "# Results - Combined - Reciprocal Rank Fusion\n",
    "# Higher score = more relevant text chunk\n",
    "\n",
    "from typing import Any, List, Dict, Tuple, Protocol\n",
    "\n",
    "\n",
    "class SearchIndex(Protocol):\n",
    "    def add_document(self, document: Dict[str, Any]) -> None: ...\n",
    "\n",
    "    def search(\n",
    "            self, query: Any, k: int = 1\n",
    "    ) -> List[Tuple[Dict[str, Any], float]]: ...\n",
    "\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self, *indexes: SearchIndex):\n",
    "        if len(indexes) == 0:\n",
    "            raise ValueError(\"Indexes must not be empty.\")\n",
    "        self._indexes = indexes\n",
    "\n",
    "    def add_document(self, document: Dict[str, Any]):\n",
    "        for index in self._indexes:\n",
    "            index.add_document(document)\n",
    "\n",
    "    def search(\n",
    "            self, query_text: str, k: int = 1, k_rrf: int = 60\n",
    "    ) -> List[Tuple[Dict[str, Any], float]]:\n",
    "        if not isinstance(query_text, str):\n",
    "            raise TypeError(\"Query text must be a string.\")\n",
    "        if k <= 0:\n",
    "            raise ValueError(\"k must be a positive integer.\")\n",
    "        if k_rrf < 0:\n",
    "            raise ValueError(\"k_rrf must be non-negative.\")\n",
    "\n",
    "        all_results = [\n",
    "            index.search(query_text, k=k * 5) for index in self._indexes\n",
    "        ]\n",
    "\n",
    "        #MERGED RESULTS RANKING\n",
    "        doc_ranks = {}\n",
    "        for idx, results in enumerate(all_results):\n",
    "            for rank, (doc, _) in enumerate(results):\n",
    "                doc_id = id(doc)\n",
    "                if doc_id not in doc_ranks:\n",
    "                    doc_ranks[doc_id] = {\n",
    "                        \"doc_obj\": doc,\n",
    "                        \"ranks\": [float(\"inf\")] * len(self._indexes),\n",
    "                    }\n",
    "                doc_ranks[doc_id][\"rank\"][idx] = rank + 1\n",
    "\n",
    "        def calc_rrf_score(ranks: List[float]) -> float:\n",
    "            return sum(1.0 / (k_rrf + r) for r in ranks if r != float(\"inf\"))\n",
    "\n",
    "        scored_docs: List[Tuple[Dict[str, Any], float]] = [\n",
    "            (ranks[\"doc_obj\"], calc_rrf_score(ranks[\"ranks\"])) for ranks in doc_ranks.values()\n",
    "        ]\n",
    "\n",
    "        filtered_docs = [\n",
    "            (doc, score) for doc, score in scored_docs if score > 0\n",
    "        ]\n",
    "        filtered_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return filtered_docs[:k]\n"
   ],
   "id": "8a2e76119ca74320",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b72119f72efd4673"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T09:59:11.940108Z",
     "start_time": "2025-09-10T09:59:11.937358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Chunk the text by section\n",
    "with open(\"./report.md\", \"r\") as f:\n",
    "    text = f.read()\n",
    "chunks = chunk_by_section(text)"
   ],
   "id": "32a669f898c79dc9",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T09:59:11.943785Z",
     "start_time": "2025-09-10T09:59:11.942328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Create a Vector Index, BM25 store (index) and create a Retriever to group them\n",
    "vector_index = VectorIndex(embedding_fn=generate_embedding)\n",
    "bm25_index = BM25Index()\n",
    "\n",
    "retriever = Retriever(vector_index, bm25_index)"
   ],
   "id": "6551f30dd7833204",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T09:59:18.474638Z",
     "start_time": "2025-09-10T09:59:18.220508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Add All Chunks to retriever, which internally passes them along to both indexes\n",
    "\n",
    "for chunk in chunks:\n",
    "    retriever.add_document({\"content\": chunk})"
   ],
   "id": "e3e639660371ca2c",
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You have not yet added your payment method in the billing page and will have reduced rate limits of 3 RPM and 10K TPM. To unlock our standard rate limits, please add a payment method in the billing page for the appropriate organization in the user dashboard (https://dashboard.voyageai.com/). Even with payment methods entered, the free tokens (200M tokens for Voyage series 3) will still apply. After adding a payment method, you should see your rate limits increase after several minutes. See our pricing docs (https://docs.voyageai.com/docs/pricing) for the free tokens for your model.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRateLimitError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 3. Add All Chunks to retriever, which internally passes them along to both indexes\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunks:\n\u001B[0;32m----> 4\u001B[0m     \u001B[43mretriever\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_document\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[28], line 24\u001B[0m, in \u001B[0;36mRetriever.add_document\u001B[0;34m(self, document)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21madd_document\u001B[39m(\u001B[38;5;28mself\u001B[39m, document: Dict[\u001B[38;5;28mstr\u001B[39m, Any]):\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indexes:\n\u001B[0;32m---> 24\u001B[0m         \u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_document\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocument\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[26], line 35\u001B[0m, in \u001B[0;36mVectorIndex.add_document\u001B[0;34m(self, document)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(content, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDocument \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be a string.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 35\u001B[0m vector \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_embedding_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_vector(vector\u001B[38;5;241m=\u001B[39mvector, document\u001B[38;5;241m=\u001B[39mdocument)\n",
      "Cell \u001B[0;32mIn[25], line 17\u001B[0m, in \u001B[0;36mgenerate_embedding\u001B[0;34m(chunks, model, input_type)\u001B[0m\n\u001B[1;32m     15\u001B[0m is_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(chunks, \u001B[38;5;28mlist\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m chunks \u001B[38;5;28;01mif\u001B[39;00m is_list \u001B[38;5;28;01melse\u001B[39;00m [chunks]\n\u001B[0;32m---> 17\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39membeddings \u001B[38;5;28;01mif\u001B[39;00m is_list \u001B[38;5;28;01melse\u001B[39;00m result\u001B[38;5;241m.\u001B[39membeddings[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/voyageai/client.py:68\u001B[0m, in \u001B[0;36mClient.embed\u001B[0;34m(self, texts, model, input_type, truncation, output_dtype, output_dimension)\u001B[0m\n\u001B[1;32m     60\u001B[0m     model \u001B[38;5;241m=\u001B[39m voyageai\u001B[38;5;241m.\u001B[39mVOYAGE_EMBED_DEFAULT_MODEL\n\u001B[1;32m     61\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m     62\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `model` argument is not specified and defaults to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvoyageai\u001B[38;5;241m.\u001B[39mVOYAGE_EMBED_DEFAULT_MODEL\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     63\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt will be a required argument in the future. We recommend to specify the model when using this \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     64\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction. Please see https://docs.voyageai.com/docs/embeddings for the list of latest models \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     65\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprovided by Voyage AI.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     66\u001B[0m     )\n\u001B[0;32m---> 68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m attempt \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_controller:\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m attempt:\n\u001B[1;32m     70\u001B[0m         response \u001B[38;5;241m=\u001B[39m voyageai\u001B[38;5;241m.\u001B[39mEmbedding\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m     71\u001B[0m             \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39mtexts,\n\u001B[1;32m     72\u001B[0m             model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     77\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_params,\n\u001B[1;32m     78\u001B[0m         )\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:445\u001B[0m, in \u001B[0;36mBaseRetrying.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    443\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, args\u001B[38;5;241m=\u001B[39m(), kwargs\u001B[38;5;241m=\u001B[39m{})\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 445\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m AttemptManager(retry_state\u001B[38;5;241m=\u001B[39mretry_state)\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:378\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[0;34m(self, retry_state)\u001B[0m\n\u001B[1;32m    376\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m action \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_state\u001B[38;5;241m.\u001B[39mactions:\n\u001B[0;32m--> 378\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43maction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:420\u001B[0m, in \u001B[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001B[0;34m(rs)\u001B[0m\n\u001B[1;32m    418\u001B[0m retry_exc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_error_cls(fut)\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreraise:\n\u001B[0;32m--> 420\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[43mretry_exc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m retry_exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfut\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexception\u001B[39;00m()\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:187\u001B[0m, in \u001B[0;36mRetryError.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mreraise\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mNoReturn:\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_attempt\u001B[38;5;241m.\u001B[39mfailed:\n\u001B[0;32m--> 187\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlast_attempt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:438\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 438\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 390\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    393\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/voyageai/client.py:70\u001B[0m, in \u001B[0;36mClient.embed\u001B[0;34m(self, texts, model, input_type, truncation, output_dtype, output_dimension)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m attempt \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_controller:\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m attempt:\n\u001B[0;32m---> 70\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[43mvoyageai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEmbedding\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_dimension\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_dimension\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m result \u001B[38;5;241m=\u001B[39m EmbeddingsObject(response)\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/voyageai/api_resources/embedding.py:20\u001B[0m, in \u001B[0;36mEmbedding.create\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m user_provided_encoding_format:\n\u001B[1;32m     18\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_format\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase64\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 20\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# This is only for the default case.\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m user_provided_encoding_format:\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/voyageai/api_resources/api_resource.py:47\u001B[0m, in \u001B[0;36mAPIResource.create\u001B[0;34m(cls, api_key, api_base, request_id, request_timeout, **params)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m     42\u001B[0m ):\n\u001B[1;32m     43\u001B[0m     requestor, url, params, headers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m__prepare_create_request(\n\u001B[1;32m     44\u001B[0m         api_key, api_base, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[1;32m     45\u001B[0m     )\n\u001B[0;32m---> 47\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     obj \u001B[38;5;241m=\u001B[39m convert_to_voyage_response(response)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/voyageai/api_resources/api_requestor.py:147\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    128\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    135\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    136\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m VoyageHttpResponse:\n\u001B[1;32m    137\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[1;32m    138\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[1;32m    139\u001B[0m         url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    145\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[1;32m    146\u001B[0m     )\n\u001B[0;32m--> 147\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/voyageai/api_resources/api_requestor.py:408\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[0;34m(self, result)\u001B[0m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_interpret_response\u001B[39m(\u001B[38;5;28mself\u001B[39m, result: requests\u001B[38;5;241m.\u001B[39mResponse) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m VoyageHttpResponse:\n\u001B[1;32m    406\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns the response(s) and a bool indicating whether it is a stream.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 408\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/voyageai/api_resources/api_requestor.py:463\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[0;34m(self, rbody, rcode, rheaders)\u001B[0m\n\u001B[1;32m    461\u001B[0m resp \u001B[38;5;241m=\u001B[39m VoyageHttpResponse(data, rheaders)\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m400\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m500\u001B[39m:\n\u001B[0;32m--> 463\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders)\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[0;31mRateLimitError\u001B[0m: You have not yet added your payment method in the billing page and will have reduced rate limits of 3 RPM and 10K TPM. To unlock our standard rate limits, please add a payment method in the billing page for the appropriate organization in the user dashboard (https://dashboard.voyageai.com/). Even with payment methods entered, the free tokens (200M tokens for Voyage series 3) will still apply. After adding a payment method, you should see your rate limits increase after several minutes. See our pricing docs (https://docs.voyageai.com/docs/pricing) for the free tokens for your model."
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T09:59:12.866792Z",
     "start_time": "2025-09-10T09:56:30.015101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = retriever.search(\n",
    "    query_text=\"what happened with INC-2023-Q4-011?\",\n",
    "    k=3  #Number of results\n",
    ")  #Search across all indexes in retriever\n",
    "\n",
    "for doc, score in results:\n",
    "    print(score, \"\\n\", doc[\"content\"][0:200], \"\\n-----\\n\")"
   ],
   "id": "a0021a6eb09db0cd",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
