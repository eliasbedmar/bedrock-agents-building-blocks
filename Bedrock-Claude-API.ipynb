{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# Bedrock Claude API\n",
    "- Application/end users -> App server - Bedrock Client -> AWS Bedrock (with User message & Model ID)\n",
    "- Focus of course - Server/Bedrock Client -> AWS Bedrock\n",
    "- Bedrock API vs Anthropic API - both hosting same LLMs - but different API and SDKs\n",
    "- Request to Bedrock - Region, Model ID, User Message\n",
    "- Not every model available in every Region\n",
    "- Inference Profiles - route requests to region where model hosted (higher throughput & performance)  - use in Model ID. Also needed for monitoring usage (CW Metrics) and Cost Tracking (Application inference profiles; user-defined). System-defined vs User-defined Inference Profiles. Also - Global Inference profiles (target all commercial regions)\n",
    "\n",
    "\n",
    "## Bedrock Runtime\n"
   ],
   "id": "6c4fe0dd7bdbe56d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7e9f4a0681780060"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\",\n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "                      )\n",
    "\n",
    "inference_profile_id = 'us.anthropic.claude-3-5-haiku-20241022-v1:0' #Global inference profile\n",
    "model_id = inference_profile_id"
   ],
   "id": "65e43d915ac68cb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# #Multi-Turn conversation\n",
    "#\n",
    "# # Make a starting list of messages\n",
    "# messages = []\n",
    "#\n",
    "# # Add in the initial user question of \"What's 1+1?\"\n",
    "# add_user_message(messages, \"What's 1+1?\")\n",
    "#\n",
    "# # Pass the list of messages into chat to get an answer\n",
    "# answer = chat(messages)\n",
    "#\n",
    "# # Take the answer and add it as an assistant message into our list\n",
    "# add_assistant_message(messages, answer)\n",
    "#\n",
    "# # Add in the user's followup question\n",
    "# add_user_message(messages, \"And 3 more added to that?\")\n",
    "#\n",
    "# # Call chat again with the list of messages to get a final answer\n",
    "# answer = chat(messages)\n",
    "# print(answer)"
   ],
   "id": "201904724900e747",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Chatbot\n",
    "# messages = []\n",
    "#\n",
    "# while True:\n",
    "#     user_input = input(\">\")\n",
    "#     add_user_message(messages, user_input)\n",
    "#     answer=chat(messages)\n",
    "#     add_assistant_message(messages, answer)\n",
    "#     print(answer)\n",
    "#\n"
   ],
   "id": "d824ff446b8efcd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Multi-Turn conversations (CONVERSE)\n",
    "- Converse Function\n",
    "- Configuration parameters (inferenceConfig) - maxTokens, temperature, StopSequences...etc\n",
    "- Prefilled Assistant Messages\n",
    "- System Prompts\n",
    "- Structured Data enforcing (for model output) = Pre-filled assistant message + StopSequences: CSV, JSON...any (you might need to use text.strip() or library like csv/JSON etc to manipulate output, clean up (e.g. newline, whitespaces...etc)"
   ],
   "id": "917e3ed409855db0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T11:38:14.429809Z",
     "start_time": "2025-09-18T11:38:14.424803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Helper Functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ]\n",
    "    }\n",
    "    messages.append(user_message)\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ]\n",
    "    }\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "def chat(messages, temperature=1.0, system=None, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"inferenceConfig\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"maxTokens\": 1000,\n",
    "            \"stopSequences\": stop_sequences\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = [{\"text\": system}]\n",
    "\n",
    "    response = client.converse(**params)\n",
    "\n",
    "    return response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ],
   "id": "8873f793bb1f5a4",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Standard conversation\n",
    "# messages = []\n",
    "#\n",
    "# add_user_message(messages, \"How di I host a PostgreSQL database?\")\n",
    "# text = chat(messages, system=\"You are an AWS Support specialist and need to answer user queries.\")"
   ],
   "id": "ffa7025d066a0d61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T11:36:44.373094Z",
     "start_time": "2025-09-18T11:36:41.120674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #Pre-filling Assistant message (i.e. biasing response)\n",
    "# messages = []\n",
    "#\n",
    "# add_user_message(messages, \"Is coffee or  tea better for breakfast?\")\n",
    "# add_assistant_message(messages, \"They are the same because\")\n",
    "#\n",
    "# chat(messages)"
   ],
   "id": "2b02d912009f545f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' everyone has different preferences. Some key differences:\\n\\nCoffee:\\n- Higher caffeine content\\n- May boost metabolism\\n- Can aid weight loss\\n- Often associated with more energy\\n- More bitter taste\\n\\nTea:\\n- Lower caffeine content\\n- Contains antioxidants\\n- Often gentler on stomach\\n- Variety of flavors\\n- Can have health benefits like reducing inflammation\\n\\nThe \"better\" choice depends on your personal taste, health goals, and how your body responds to each beverage.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T11:47:01.362554Z",
     "start_time": "2025-09-18T11:47:00.329022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Structured Data\n",
    "#Using Pre-filling message + Stop sequences\n",
    "\n",
    "messages = []\n",
    "\n",
    "prompt = \"\"\"\n",
    "Generate three different sample AWS CLI commands. Each should be very short.\n",
    "\"\"\"\n",
    "\n",
    "add_user_message(messages, prompt)\n",
    "add_assistant_message(\n",
    "    messages,\n",
    "    \"Here are all three commands in a single block without any comments:\\n```bash\",\n",
    ")\n",
    "\n",
    "text = chat(messages, stop_sequences=[\"```\"])\n",
    "text.strip()\n"
   ],
   "id": "eaab15dcd5a0dd4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aws s3 ls\\naws ec2 describe-instances\\naws iam list-users'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T11:47:02.436041Z",
     "start_time": "2025-09-18T11:47:02.408200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Cleaning up structured data output\n",
    "import json\n",
    "\n",
    "# Parse as JSON to validate and format\n",
    "parsed_data = json.loads(text.strip())\n",
    "\n",
    "#Other data types text.strip()\n",
    "parsed_data\n"
   ],
   "id": "f47ce442bee5ff98",
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[66], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Parse as JSON to validate and format\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m parsed_data \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrip\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m parsed_data\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONDecoder\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w\u001B[38;5;241m=\u001B[39mWHITESPACE\u001B[38;5;241m.\u001B[39mmatch):\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    containing a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m     end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    353\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscan_once(s, idx)\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Streaming Conversations\n",
    "- ```converse_stream()```\n",
    "- ContextBlockDelta events key"
   ],
   "id": "457ce9329060bbd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T11:29:35.773007Z",
     "start_time": "2025-09-18T11:29:28.823441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = []\n",
    "add_user_message(messages, \"How di I host a PostgreSQL database?\")\n",
    "response = client.converse_stream(messages=messages, modelId=model_id)\n",
    "for event in response[\"stream\"]:\n",
    "    if \"contentBlockDelta\" in event:\n",
    "        chunk = event[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "        print(chunk, end=\"\")\n",
    "        text += chunk\n",
    "\n",
    "print(\"\\n\\nTotal Message:\\n\" + text)\n"
   ],
   "id": "b1759bcfaeb537e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are several ways to host a PostgreSQL database:\n",
      "\n",
      "1. Local Installation\n",
      "- Download PostgreSQL from official website\n",
      "- Install on your local machine\n",
      "- Use default localhost connection\n",
      "\n",
      "2. Cloud Platforms\n",
      "a) Amazon RDS\n",
      "- Managed PostgreSQL service\n",
      "- Easy setup\n",
      "- Scalable and secure\n",
      "- Pay per usage\n",
      "\n",
      "b) Google Cloud SQL\n",
      "- Fully managed PostgreSQL database\n",
      "- Automatic backups\n",
      "- Automatic replication\n",
      "\n",
      "c) Azure Database for PostgreSQL\n",
      "- Managed service by Microsoft\n",
      "- Supports single server and flexible server modes\n",
      "- Built-in security features\n",
      "\n",
      "3. Self-Hosted Options\n",
      "a) Virtual Private Server (VPS)\n",
      "- Providers like DigitalOcean, Linode\n",
      "- Full control over database\n",
      "- Manual configuration required\n",
      "\n",
      "b) Kubernetes\n",
      "- Container-based deployment\n",
      "- Using Helm charts\n",
      "- Scalable and portable\n",
      "\n",
      "4. Managed Hosting Services\n",
      "- Heroku Postgres\n",
      "- ElephantSQL\n",
      "- Render\n",
      "- Supabase\n",
      "\n",
      "5. Docker Deployment\n",
      "```bash\n",
      "docker run --name postgres-db \\\n",
      "  -e POSTGRES_PASSWORD=mypassword \\\n",
      "  -p 5432:5432 \\\n",
      "  -d postgres\n",
      "```\n",
      "\n",
      "Recommended steps:\n",
      "1. Choose hosting method\n",
      "2. Configure security\n",
      "3. Set up backups\n",
      "4. Monitor performance\n",
      "\n",
      "Considerations:\n",
      "- Budget\n",
      "- Performance needs\n",
      "- Scalability\n",
      "- Maintenance requirements\n",
      "\n",
      "Total Message:\n",
      "To host a PostgreSQL database on AWS, you have several options:\n",
      "\n",
      "1. Amazon RDS (Recommended for most use cases):\n",
      "- Fully managed relational database service\n",
      "- Easy to set up and maintain\n",
      "- Supports PostgreSQL\n",
      "- Features:\n",
      "  * Automatic backups\n",
      "  * Patch management\n",
      "  * Scalability\n",
      "  * Multi-AZ deployments\n",
      "- Steps to create:\n",
      "  1. Go to Amazon RDS in AWS Console\n",
      "  2. Click \"Create database\"\n",
      "  3. Choose PostgreSQL\n",
      "  4. Select configuration (size, performance needs)\n",
      "  5. Configure network and security settings\n",
      "  6. Create the database\n",
      "\n",
      "2. Amazon Aurora PostgreSQL:\n",
      "- Fully managed, PostgreSQL-compatible database\n",
      "- Higher performance\n",
      "- Automatic scaling\n",
      "- Compatible with PostgreSQL\n",
      "\n",
      "3. EC2 Self-Managed:\n",
      "- More control but requires manual management\n",
      "- Steps:\n",
      "  1. Launch EC2 instance\n",
      "  2. Install PostgreSQL manually\n",
      "  3. Configure security groups\n",
      "  4. Manage updates and backups yourself\n",
      "\n",
      "4. Amazon Lightsail:\n",
      "- Simplified option for smaller projects\n",
      "- Easy to set up\n",
      "- Lower cost\n",
      "- Limited scalability\n",
      "\n",
      "Recommendation: For most production environments, use Amazon RDS or Aurora PostgreSQL for ease of management and built-in features.\n",
      "\n",
      "Would you like me to elaborate on any of these options?Here are several ways to host a PostgreSQL database:\n",
      "\n",
      "1. Local Installation\n",
      "- Download PostgreSQL from official website\n",
      "- Install on your local machine\n",
      "- Use default localhost connection\n",
      "\n",
      "2. Cloud Platforms\n",
      "a) Amazon RDS\n",
      "- Managed PostgreSQL service\n",
      "- Easy setup\n",
      "- Scalable and secure\n",
      "- Pay per usage\n",
      "\n",
      "b) Google Cloud SQL\n",
      "- Fully managed PostgreSQL database\n",
      "- Automatic backups\n",
      "- Automatic replication\n",
      "\n",
      "c) Azure Database for PostgreSQL\n",
      "- Managed service by Microsoft\n",
      "- Supports single server and flexible server modes\n",
      "- Built-in security features\n",
      "\n",
      "3. Self-Hosted Options\n",
      "a) Virtual Private Server (VPS)\n",
      "- Providers like DigitalOcean, Linode\n",
      "- Full control over database\n",
      "- Manual configuration required\n",
      "\n",
      "b) Kubernetes\n",
      "- Container-based deployment\n",
      "- Using Helm charts\n",
      "- Scalable and portable\n",
      "\n",
      "4. Managed Hosting Services\n",
      "- Heroku Postgres\n",
      "- ElephantSQL\n",
      "- Render\n",
      "- Supabase\n",
      "\n",
      "5. Docker Deployment\n",
      "```bash\n",
      "docker run --name postgres-db \\\n",
      "  -e POSTGRES_PASSWORD=mypassword \\\n",
      "  -p 5432:5432 \\\n",
      "  -d postgres\n",
      "```\n",
      "\n",
      "Recommended steps:\n",
      "1. Choose hosting method\n",
      "2. Configure security\n",
      "3. Set up backups\n",
      "4. Monitor performance\n",
      "\n",
      "Considerations:\n",
      "- Budget\n",
      "- Performance needs\n",
      "- Scalability\n",
      "- Maintenance requirements\n"
     ]
    }
   ],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
